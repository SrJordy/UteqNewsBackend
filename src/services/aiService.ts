import Groq from 'groq-sdk';
import { searchContext } from './vectorService';

// Configuraci√≥n de Groq
const GROQ_API_KEY = process.env.GROQ_API_KEY;

// Modelos gratuitos disponibles en Groq (ordenados por capacidad)
const GROQ_MODELS = {
    // Modelos m√°s capaces
    LLAMA_70B: 'llama-3.3-70b-versatile',      // Muy potente, m√°s lento
    LLAMA_8B: 'llama-3.1-8b-instant',           // R√°pido y bueno
    GEMMA_9B: 'gemma2-9b-it',                   // Google Gemma 2
    MIXTRAL: 'mixtral-8x7b-32768',              // Mixtral de Mistral
};

// Modelo por defecto para el chatbot
const DEFAULT_MODEL = GROQ_MODELS.LLAMA_70B;

if (!GROQ_API_KEY) {
    console.warn('‚ö†Ô∏è GROQ_API_KEY no est√° definida. El chat de IA no funcionar√° correctamente.');
}

// Inicializar cliente de Groq
const groq = new Groq({
    apiKey: GROQ_API_KEY,
});

/**
 * Pregunta a la IA usando RAG (B√∫squeda Vectorial) para el contexto.
 * @param question - La pregunta del usuario.
 * @returns La respuesta de la IA.
 */
export const askAI = async (question: string): Promise<string> => {
    let context = '';

    try {
        // 1. Obtener contexto relevante usando b√∫squeda vectorial
        console.log(`üîç Buscando contexto para: "${question}"...`);
        context = await searchContext(question, 3);
        console.log(`üìö Contexto encontrado: ${context.length > 0 ? 'S√≠' : 'No'}`);
    } catch (error) {
        console.error('‚ùå Error al obtener contexto vectorial:', error);
        context = 'No se pudo obtener informaci√≥n detallada en este momento.';
    }

    try {
        const systemPrompt = `Eres el asistente virtual de la carrera de Ingenier√≠a en Software de la UTEQ (Universidad T√©cnica Estatal de Quevedo).

PERSONALIDAD:
- Eres amigable, cercano y hablas de t√∫ a t√∫ con los estudiantes
- Usas un tono casual pero profesional
- Puedes usar emojis ocasionalmente para hacer la conversaci√≥n m√°s amena

INSTRUCCIONES:
1. Responde DIRECTAMENTE a la pregunta del usuario bas√°ndote en el CONTEXTO proporcionado
2. Tu respuesta debe ser en ESPA√ëOL
3. Si no encuentras informaci√≥n en el contexto pero es una pregunta general sobre la carrera o la universidad, responde con tu conocimiento general
4. Si la pregunta no tiene relaci√≥n con la UTEQ, la carrera de software o temas acad√©micos, amablemente indica que est√°s especializado en esos temas
5. S√© conciso pero √∫til - no te extiendas innecesariamente

CONTEXTO (RAG):
${context || 'No hay contexto espec√≠fico disponible.'}`;

        console.log(`ü§ñ Consultando a Groq (${DEFAULT_MODEL})...`);
        const startTime = Date.now();

        const response = await groq.chat.completions.create({
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: question }
            ],
            model: DEFAULT_MODEL,
            temperature: 0.7,
            max_tokens: 1024,
        });

        const endTime = Date.now();
        console.log(`‚ö° Respuesta recibida en ${endTime - startTime}ms`);

        const text = response.choices?.[0]?.message?.content;

        if (text) {
            return text.trim();
        }
    } catch (error: any) {
        console.error(`‚ùå Error con Groq:`, error.message);

        if (error.status === 401) {
            return 'Error de autenticaci√≥n: Verifica tu GROQ_API_KEY.';
        }

        if (error.status === 429) {
            return 'Estoy un poco ocupado ahora mismo. ¬øPuedes intentar de nuevo en unos segundos? üòÖ';
        }

        return 'Lo siento, tuve un problema t√©cnico. ¬øPuedes intentar de nuevo? üîß';
    }

    return 'No pude generar una respuesta. ¬øPuedes reformular tu pregunta?';
};

/**
 * Funci√≥n de prueba para comparar modelos de Groq
 */
export const testGroqModels = async (testQuestion: string = '¬øCu√°l es la malla curricular de Ingenier√≠a en Software?') => {
    console.log('\nüß™ === PRUEBA DE MODELOS GROQ ===\n');
    console.log(`üìù Pregunta de prueba: "${testQuestion}"\n`);

    const models = [
        { name: 'LLaMA 3.3 70B', id: GROQ_MODELS.LLAMA_70B },
        { name: 'LLaMA 3.1 8B', id: GROQ_MODELS.LLAMA_8B },
        { name: 'Gemma 2 9B', id: GROQ_MODELS.GEMMA_9B },
        { name: 'Mixtral 8x7B', id: GROQ_MODELS.MIXTRAL },
    ];

    for (const model of models) {
        console.log(`\nüìä Probando: ${model.name} (${model.id})`);
        console.log('-'.repeat(50));

        try {
            const startTime = Date.now();

            const response = await groq.chat.completions.create({
                messages: [
                    {
                        role: 'system',
                        content: 'Eres un asistente de la carrera de Ingenier√≠a en Software de la UTEQ. Responde de forma concisa en espa√±ol.'
                    },
                    { role: 'user', content: testQuestion }
                ],
                model: model.id,
                temperature: 0.7,
                max_tokens: 512,
            });

            const endTime = Date.now();
            const responseTime = endTime - startTime;
            const text = response.choices?.[0]?.message?.content;
            const tokens = response.usage;

            console.log(`‚è±Ô∏è  Tiempo: ${responseTime}ms`);
            console.log(`üìä Tokens: ${tokens?.prompt_tokens} entrada, ${tokens?.completion_tokens} salida`);
            console.log(`üí¨ Respuesta (primeros 200 chars):`);
            console.log(`   "${text?.substring(0, 200)}..."`);

        } catch (error: any) {
            console.log(`‚ùå Error: ${error.message}`);
        }
    }

    console.log('\nüèÅ === FIN DE PRUEBAS ===\n');
};